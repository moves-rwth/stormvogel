// MDP from lecture at Radboud
@type: MDP
@parameters

@reward_models

@nr_states
4
@nr_choices
6
@model
state 0 init
	action blue
        	0 : 0.25
		2 : 0.5
		3 : 0.25
	action black
		1 : 1.0
state 1
	action red
		0 : 0.5
		1 : 0.1
		2 : 0.4
state 2 a
	action loop
		2 : 1.0
state 3
	action loop
		3 : 1.0
	action continue
		2 : 1.0
